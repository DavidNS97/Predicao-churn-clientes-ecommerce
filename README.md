# Predi√ß√£o de Churn em E-commerce com Machine Learning
<p align="left">
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54"/>
  <img src="https://img.shields.io/badge/STATUS-EM%20ANDAMENTO-orange" alt="Status: Em Andamento"/>
</p>

## 1. Introdu√ß√£o

Este projeto apresenta uma solu√ß√£o completa de **predi√ß√£o de churn de clientes em e-commerce**, utilizando t√©cnicas de **Machine Learning** aplicadas a dados comportamentais e transacionais.

**Churn** trata-se de cancelamento ou abandono do cliente, ou seja, quando um cliente deixa de comprar ou se relacionar com a empresa. Antecipar esse comportamento permite agir de forma proativa para aumentar reten√ß√£o e reduzir perdas de receita.

O objetivo da solu√ß√£o √© estimar a **probabilidade de churn de cada cliente** e para al√©m da an√°lise, disponibilizar essa informa√ß√£o de forma pr√°tica, permitindo a execu√ß√£o de a√ß√µes de reten√ß√£o com base em diferentes n√≠veis de risco.

Al√©m da modelagem preditiva, todo o pipeline foi desenvolvido seguindo **boas pr√°ticas de ci√™ncia de dados**, incluindo an√°lise explorat√≥ria, engenharia de features, valida√ß√£o out-of-time, sele√ß√£o de vari√°veis, compara√ß√£o de modelos e disponibiliza√ß√£o dos resultados em uma aplica√ß√£o interativa.

üëâ **Acesse o aplicativo interativo:**  
https://app-predicao-churn-ecommerce.streamlit.app/ (clique com o bot√£o direito ‚Üí Abrir em nova guia)

‚ÑπÔ∏è *Observa√ß√£o: na primeira execu√ß√£o o aplicativo pode levar alguns segundos para carregar, pois o ambiente √© inicializado sob demanda pelo Streamlit.*

## 2. Dicion√°rio de Dados

| Coluna                                   | Tipo       | Descri√ß√£o |
|------------------------------------------|------------|-----------|
| ID do Cliente                            | Num√©rica   | ID √∫nico do cliente |
| Churn                                    | Bin√°ria    | Indicador de churn (sa√≠da do cliente) |
| Tempo de Relacionamento                  | Num√©rica   | Tempo de relacionamento do cliente com a empresa (anos) |
| Dispositivo de Login Preferido           | Categ√≥rica | Dispositivo de login preferido do cliente |
| N√≠vel da Cidade                          | Categ√≥rica | N√≠vel da cidade (1 = grandes capitais; 2 = cidades m√©dias; 3 = cidades pequenas) |
| Armaz√©m at√© a Casa                       | Num√©rica   | Dist√¢ncia entre o armaz√©m e a casa do cliente (km) |
| M√©todo de Pagamento Preferido            | Categ√≥rica | M√©todo de pagamento preferido do cliente |
| G√™nero                                   | Categ√≥rica | G√™nero do cliente |
| Horas no App                             | Num√©rica   | N√∫mero de horas gastas no aplicativo ou site |
| N√∫mero de Dispositivos Registrados       | Num√©rica   | Total de dispositivos registrados para o cliente |
| Categoria de Pedido Preferida            | Categ√≥rica | Categoria de pedido preferida do cliente no √∫ltimo m√™s |
| Pontua√ß√£o de Satisfa√ß√£o                  | Num√©rica   | Pontua√ß√£o de satisfa√ß√£o do cliente com o servi√ßo |
| Estado Civil                             | Categ√≥rica | Estado civil do cliente |
| N√∫mero de Endere√ßos                      | Num√©rica   | Total de endere√ßos adicionados pelo cliente |
| Reclama√ß√£o                               | Bin√°ria    | Se houve alguma reclama√ß√£o no √∫ltimo m√™s |
| Aumento do Valor de Pedido vs Ano Anterior | Num√©rica | Percentual de aumento nos pedidos em rela√ß√£o ao ano anterior |
| Cupons Usados                            | Num√©rica   | Total de cupons usados no √∫ltimo m√™s |
| Quantidade de Pedidos                    | Num√©rica   | Total de pedidos realizados no √∫ltimo m√™s |
| Dias Desde √öltimo Pedido                 | Num√©rica   | Dias desde o √∫ltimo pedido do cliente |
| Valor de Cashback                        | Num√©rica   | Valor m√©dio de cashback no √∫ltimo m√™s |


## 3. Prepara√ß√£o dos Dados

A etapa de prepara√ß√£o dos dados teve como objetivo garantir a qualidade e a consist√™ncia das informa√ß√µes antes da constru√ß√£o do modelo de Machine Learning.

### Carregamento
Os dados foram carregados a partir de um arquivo Excel (`E Commerce Dataset.xlsx`, aba *E Comm*).

## Ajuste de Tipos de Dados

Algumas vari√°veis vieram com tipos inadequados no dataset original e foram ajustadas para refletir melhor sua natureza:
- **Reclama√ß√£o** ‚Üí veio como num√©rica (0/1), mas foi convertida para **booleano**.  
  *Motivo:* representa apenas presen√ßa ou aus√™ncia de reclama√ß√£o, n√£o uma escala num√©rica.
- **N√≠vel da Cidade** ‚Üí veio como num√©rica (1, 2, 3), mas foi convertida para **categ√≥rica**.  
  *Motivo:* os valores indicam categorias de cidades (1 = grandes capitais, 2 = cidades m√©dias, 3 = cidades pequenas), n√£o uma ordem cont√≠nua.

Esses ajustes garantem que os algoritmos de machine learning interpretem corretamente as vari√°veis e evitem distor√ß√µes estat√≠sticas.

### An√°lise de Valores Ausentes
O objetivo desta etapa foi verificar a qualidade dos dados e identificar vari√°veis com valores faltantes.  
Essa an√°lise √© muito importante, pois:
- **Garante confiabilidade**: valores ausentes podem distorcer estat√≠sticas e comprometer o desempenho dos modelos.  
- **Orienta o tratamento posterior**: ao saber qual percentual de missing em cada variavel, √© poss√≠vel decidir se ser√° feita imputa√ß√£o, exclus√£o ou outro tipo de ajuste.  
- **Avalia impacto na amostra**: como o percentual m√°ximo de missing foi de ~5,5% e concentrado em vari√°veis num√©ricas, consideramos seguro aplicar t√©cnicas de imputa√ß√£o sem preju√≠zo relevante para o dataset.  

#### Principais vari√°veis com valores ausentes
| Vari√°vel                                   | Qtde Vazios | % Vazios |
|--------------------------------------------|-------------|----------|
| Dias Desde √öltimo Pedido                   | 307         | 5.45%    |
| Aumento do Valor de Pedido vs Ano Anterior | 265         | 4.71%    |
| Tempo de Relacionamento                    | 264         | 4.69%    |
| Quantidade de Pedidos                      | 258         | 4.58%    |
| Cupons Usados                              | 256         | 4.55%    |
| Horas no App                               | 255         | 4.53%    |
| Armaz√©m at√© a Casa                         | 251         | 4.46%    |



## 4. Feature Engineering

Nesta etapa foram criadas novas vari√°veis (features) para  capturar padr√µes adicionais no comportamento dos clientes que n√£o estavam explicitamente representados nas colunas originais.


### Novas vari√°veis criadas
| Vari√°vel                | F√≥rmula / Origem                                                                 | Objetivo |
|--------------------------|----------------------------------------------------------------------------------|----------|
| **pedidos_por_ano_rel** | `Quantidade de Pedidos / (Tempo de Relacionamento + 0.1)`                        | Frequ√™ncia real de consumo considerando o tempo de relacionamento |
| **rf_score**            | `Quantidade de Pedidos / (Dias Desde √öltimo Pedido + 0.1)`                       | Rec√™ncia x Frequ√™ncia: clientes que compram muito e recentemente t√™m score maior |
| **intensidade_uso**     | `Horas no App / (Quantidade de Pedidos + 0.1)`                                   | Engajamento de compra no app (diferenciar quem compra de quem s√≥ navega) |
| **insatisfacao_recente**| `Reclama√ß√£o * (6 - Pontua√ß√£o de Satisfa√ß√£o)`                                     | Combina reclama√ß√£o recente com baixa satisfa√ß√£o percebida |
| **distancia_por_pedido**| `Armaz√©m at√© a Casa / (Quantidade de Pedidos + 0.1)`                             | Avaliar impacto da dist√¢ncia log√≠stica por pedido |
| **dispositivos_por_pedido** | `N√∫mero de Dispositivos Registrados / (Quantidade de Pedidos + 0.1)`         | Relacionar dispositivos vinculados ao volume de pedidos |

Uma soma (+0.1) foi utilizado nas divis√µes para evitar erros de divis√£o por zero.


### Impacto no modelo
Antes da cria√ß√£o dessas vari√°veis derivadas, o modelo apresentava **acur√°cia abaixo de 50%**.  
Ap√≥s a inclus√£o das novas features, houve um ganho significativo de desempenho, mostrando que o *feature engineering* foi decisivo para melhorar a capacidade preditiva.

## 5. Estrat√©gia de Valida√ß√£o

Para garantir que o modelo fosse avaliado de forma robusta, adotamos uma estrat√©gia de valida√ß√£o em m√∫ltiplos n√≠veis:

### 5.1 Separa√ß√£o Out-of-Time (OOT)
- Objetivo: avaliar se o modelo mant√©m desempenho em cen√°rios fora do per√≠odo de treino e teste, ou seja, num cenario real, ao receber dados novos o modelo ser√° testado se √© capaz de lidar com dados diferentes do passado.
- Como o dataset n√£o possui uma coluna de data, utilizamos **Tempo de Relacionamento** como proxy temporal.  
- Clientes mais recentes (quartil inferior de tempo de relacionamento) foram separados como conjunto **OOT**, simulando clientes novos.  

### 5.2 Defini√ß√£o de Features e Target
- **Target:** `Churn` (indicador de sa√≠da do cliente).  
- **Features:** todas as demais vari√°veis inclusive as criadas na feature engineering.  

### 5.3 Split Treino / Teste
- O conjunto de treino foi dividido da base que sobrou em **treino (80%)** e **teste (20%)**.  
- Utilizamos **estratifica√ß√£o** para manter a taxa de churn equivalente entre os conjuntos.  
- Isso garante que a propor√ß√£o de clientes churn vs n√£o churn seja preservada.

### 5.4 Verifica√ß√£o de Balanceamento
Ap√≥s realizar o split entre treino e teste, verificamos se a taxa de churn permaneceu equivalente nos diferentes conjuntos.  
Isso √© importante porque:

- **Evita vi√©s**: se o treino tivesse muito mais casos de churn que o teste (ou vice‚Äëversa), o modelo poderia aprender padr√µes artificiais.  
- **Valida a estratifica√ß√£o**: confirma que a divis√£o preservou a distribui√ß√£o da vari√°vel alvo assegurando que o modelo seja avaliado em condi√ß√µes pr√≥ximas √†s reais.

Resultados:
- Taxa de churn geral: ~5,79%  
- Taxa de churn treino: ~5,81%  
- Taxa de churn teste: ~5,74%
  
As taxas s√£o praticamente iguais, mostrando que o split foi bem sucedido e que o modelo ser√° treinado e avaliado em bases compar√°veis.


#### Fluxograma separa√ß√£o dos dados



## 6. An√°lise Explorat√≥ria dos Dados (EDA)

Nesta etapa foram realizadas an√°lises estat√≠sticas e visuais para compreender melhor o comportamento das vari√°veis e sua rela√ß√£o com o churn.

### 6.1 Estat√≠sticas Descritivas ‚Äî Vari√°veis Num√©ricas
- M√©dia e mediana calculadas por classe (`Churn` vs `N√£o Churn`).
- Criada a m√©trica **diff_rel** para identificar vari√°veis mais discriminativas.

O grafico de barras abaixo mostra as principais vari√°veis num√©ricas com suas m√©dia por classe de churn e a raz√£o relativa (`diff_rel`).
Valores maiores que 1 indicam que a vari√°vel tende a ser maior em clientes **n√£o churn**, enquanto valores menores que 1 indicam maior associa√ß√£o com **churn**.




**Insights principais:**
- Clientes churn tendem a ter **menos dias desde o √∫ltimo pedido** e **menor tempo de relacionamento**.
- Vari√°veis como **insatisfa√ß√£o recente**, **n√∫mero de endere√ßos** e **rf_score** aparecem mais altas em clientes churn.
- O uso de **cupons** tamb√©m √© relativamente maior em churners.
  
### 6.2 Matriz de Correla√ß√£o ‚Äî Vari√°veis Num√©ricas
- Objetivo: identificar rela√ß√µes fortes e poss√≠veis redund√¢ncias.

IMAGEM


**Insights principais da correla√ß√£o:**
- Algumas vari√°veis apresentam alta correla√ß√£o entre si (ex.: Quantidade de Pedidos e Pedidos por Ano), indicando redund√¢ncia.  
- Vari√°veis como **Insatisfa√ß√£o Recente** e **Dias Desde √öltimo Pedido** t√™m correla√ß√£o mais baixa com as demais features, sugerindo maior poder explicativo isolado para churn.  

### 6.3 Estat√≠sticas Descritivas ‚Äî Vari√°veis Categ√≥ricas
- Para cada vari√°vel categ√≥rica, calculada a propor√ß√£o de churn e n√£o churn.
- Criada a m√©trica **diff_rel** para medir poder discriminativo relativo.

| Vari√°vel                        | Categoria              | %N√£o Churn | %Churn | diff_rel |
|---------------------------------|------------------------|------------|--------|----------|
| Dispositivo de Login Preferido  | Computer               | 93.69      | 6.31   | 0.07     |
| Dispositivo de Login Preferido  | Mobile Phone           | 94.20      | 5.80   | 0.06     |
| N√≠vel da Cidade                 | 3                      | 90.50      | 9.50   | 0.10     |
| N√≠vel da Cidade                 | 2                      | 97.76      | 2.24   | 0.02     |
| M√©todo de Pagamento Preferido   | E-wallet               | 89.01      | 10.99  | 0.12     |
| M√©todo de Pagamento Preferido   | UPI                    | 98.30      | 1.70   | 0.02     |
| Categoria de Pedido Preferida   | Fashion                | 90.91      | 9.09   | 0.10     |
| Categoria de Pedido Preferida   | Grocery                | 95.87      | 4.13   | 0.04     |
| Estado Civil                    | Single                 | 91.12      | 8.88   | 0.10     |
| Estado Civil                    | Married                | 95.64      | 4.36   | 0.05     |
| Reclama√ß√£o                      | True                   | 87.70      | 12.30  | 0.14     |
| Reclama√ß√£o                      | False                  | 96.58      | 3.42   | 0.04     |

**Insights principais:**
- **Maior churn** em clientes com **reclama√ß√µes**, que usam **E-wallet**,  e compram **Fashion/Mobile**.  
- **Menor churn** em clientes que usam **UPI**, compram **Laptop & Accessory** e n√£o registram reclama√ß√µes.


## 7. Prepara√ß√£o para Modelagem

### 7.1 Remo√ß√£o de vari√°veis irrelevantes
- A coluna **ID do Cliente** foi removida dos conjuntos de treino, teste e OOT por se tratar de  apenas de um identificador √∫nico, sem poder preditivo, e poderia induzir o modelo a padr√µes artificiais.

### 7.2 Imputa√ß√£o de valores ausentes
-Ap√≥s identificar as vari√°veis com valores faltantes na etapa de "Prepara√ß√£o dos Dados" chegou a hora de tratar esses valores nulos, pois n√£o s√£o aceitos nos principais algoritmos de ML
- Apenas colunas **num√©ricas** apresentavam valores faltantes.  
- Foi utilizada a **mediana** para imputa√ß√£o, pois √© s√≥lida contra outliers, ou seja, valores extremos n√£o distorcem o preenchimento e preserva a distribui√ß√£o das vari√°veis num√©ricas.
- O calculo foi  feito considerando  **apenas no conjunto de treino** para evitar vazamento de informa√ß√£o ja que o modelo de teste e OOT s√£o dados "novos", e considerar-los poderia enviesar o modelo.
- A transforma√ß√£o foi aplicada posteriormente nos conjuntos de teste e OOT.

### 7.3 Codifica√ß√£o de vari√°veis categ√≥ricas
- As vari√°veis categ√≥ricas foram convertidas em **dummies (one-hot encoding)** para que o modelo consiga interpretar corretamente categorias n√£o num√©ricas. Esse processo evita que o algoritmo crie rela√ß√µes artificiais entre categorias (como se houvesse uma ordem entre elas) e garante que cada categoria seja representada de forma independente em colunas bin√°rias (0/1). 
- Ap√≥s a codifica√ß√£o, os conjuntos de treino, teste e OOT foram **reindexados** para garantir que todos possu√≠ssem as mesmas colunas para garantir consist√™ncia estrutural e comparabilidade, para que assim o modelo consiga aplicar o mesmo racioc√≠nio em qualquer dado novo.

#### Fluxograma da prepara√ß√£o dos dados

## 8. Sele√ß√£o das Melhores Features

Ap√≥s a prepara√ß√£o dos dados, foi necess√°rio selecionar as vari√°veis mais relevantes para o modelo de churn.  Essa etapa √© importante pois √© nela que reduz a dimensionalidade dos dados para manter apenas vari√°veis que realmente contribuem para a previs√£o.
Embora a **An√°lise Explorat√≥ria (EDA)** seja √∫til para identificar correla√ß√µes e padr√µes, ela n√£o captura totalmente a **import√¢ncia preditiva** das vari√°veis.  

Por isso, gosto de  utilizar  **√°rvore de decis√£o** para calcular a import√¢ncia das features.  
Esse m√©todo tem como vantagens:
- Considera intera√ß√µes n√£o lineares entre vari√°veis.  
- Avalia o impacto direto de cada feature na redu√ß√£o da impureza dos n√≥s da √°rvore.  
- √â mais completo que apenas observar correla√ß√µes, j√° que algumas vari√°veis podem ser pouco correlacionadas isoladamente, mas altamente relevantes em conjunto.  

### Processo
1. Calculamos a import√¢ncia de cada vari√°vel com base no modelo de √°rvore nos dados de **TREINO**.  
2. Ordenamos as features por import√¢ncia.  
3. Criamos uma coluna de **import√¢ncia acumulada**.  
4. Selecionamos as vari√°veis respons√°veis por **95% da import√¢ncia total**.  

### Resultado
As vari√°veis selecionadas (best_features) representam o subconjunto mais relevante para explicar o churn, .


## 9 Random Forest

O algoritmo **Random Forest** foi testado pela sua  capacidade de lidar com vari√°veis num√©ricas e categ√≥ricas, al√©m de  combinar resultados de m√∫ltiplas √°rvores de decis√£o para produzir previs√µes mais est√°veis e generaliz√°veis
Para garantir o melhor desempenho, aplicamos uma busca sistem√°tica de par√¢metros (GridSearchCV).

### O que foi feito
- Definimos um conjunto de **par√¢metros candidatos** (como n√∫mero de √°rvores, tamanho m√≠nimo das folhas e crit√©rio de divis√£o).
- O **GridSearchCV** testou todas as combina√ß√µes poss√≠veis desses par√¢metros.
- Cada combina√ß√£o foi avaliada com **valida√ß√£o cruzada (cv=3)** usando a m√©trica **ROC AUC**.
- O processo escolheu automaticamente a configura√ß√£o que apresentou o melhor resultado.

### Par√¢metros testados
Foram avaliadas diferentes combina√ß√µes de par√¢metros para encontrar o melhor equil√≠brio entre **complexidade do modelo** e **capacidade de generaliza√ß√£o**:
- `min_samples_leaf`: [15, 20, 25, 30, 50]     - Relacionado ao n√∫mero m√≠nimo de amostras necess√°rias para que um n√≥ folha seja criado
- `n_estimators`: [100, 200, 500, 1000]        - Relacionado ao n√∫mero de modelos individuais (√°rvores de decis√£o) que ser√£o constru√≠dos
- `criterion`: ['gini', 'entropy', 'log_loss'] - Define  a fun√ß√£o de avalia√ß√£o usada para escolher os melhores splits nas √°rvores.

### Resultado
O modelo final foi treinado com os **melhores par√¢metros encontrados**, garantindo maior capacidade preditiva e menor risco de overfitting.

### Pipeline
Foi criado um **pipeline** integrando o modelo Random Forest com o GridSearchCV, garantindo organiza√ß√£o e reprodutibilidade do processo de treinamento.

### Treinamento
O pipeline foi aplicado nos dados de treino, utilizando as **best_features** e os **par√¢metros otimizados** pelo GridSearchCV.

## 10 Regress√£o Log√≠stica

A **Regress√£o Log√≠stica** foi utilizada como modelo baseline por sua simplicidade e interpretabilidade ( esse modelo em especifico, pude estudar muito no periodo da faculdade)
Assim como na Random Forest, aplicamos a  otimiza√ß√£o de par√¢metros e para melhorar a representa√ß√£o das vari√°veis cont√≠nuas, aplicamos etapas de discretiza√ß√£o, algo que n√£o √© necess√°rio na arvore de decisao.

### O que foi feito

- **Discretiza√ß√£o supervisionada:** as vari√°veis num√©ricas cont√≠nuas foram transformadas em bins (intervalos) usando √°rvores de decis√£o.  
  Essa t√©cnica divide os valores em faixas que ajudam o modelo a aprender melhor, permitindo capturar padr√µes n√£o lineares, reduzir o impacto de outliers e facilitar a interpreta√ß√£o.  
  - Sem a discretiza√ß√£o, o modelo perdeu aproximadamente **22% de poder discriminativo (AUC)** e **15% de acur√°cia no OOT**.
- **One-Hot Encoding:** os bins resultantes foram convertidos em vari√°veis categ√≥ricas bin√°rias.  
  Essa etapa √© importante porque evita que os intervalos sejam interpretados como valores num√©ricos cont√≠nuos, garantindo que cada faixa seja tratada como uma categoria independente.  
- O GridSearchCV  testou todas as combina√ß√µes poss√≠veis dos  par√¢metros selecionados 
- Cada combina√ß√£o foi avaliada com **valida√ß√£o cruzada (cv=3)** usando **ROC AUC**, e selecionamos automaticamente a configura√ß√£o com melhor desempenho.

### Par√¢metros testados
- `penalty`: ["l1", "l2"] - tipo de regulariza√ß√£o aplicada.  
- `C`: [0.01, 0.1, 1, 10, 100] - controla a for√ßa da regulariza√ß√£o (valores menores = regulariza√ß√£o mais forte).  

### Pipeline
Foi criado um **pipeline completo**, integrando:
1. Discretiza√ß√£o supervisionada  
2. One-Hot Encoding  
3. GridSearchCV com regress√£o log√≠stica  

### Treinamento
O pipeline foi aplicado nos dados de treino, utilizando as **best_features** e os **par√¢metros otimizados** pelo GridSearchCV.

## 10. Avalia√ß√£o dos Modelos
### M√©tricas utilizadas
- **Acur√°cia**: propor√ß√£o de previs√µes corretas.
- **AUC (√Årea sob a curva ROC)**: capacidade do modelo em separar classes.

### Resultados

| Modelo               | Acur√°cia Treino | AUC Treino | Acur√°cia Teste | AUC Teste | Acur√°cia OOT | AUC OOT |
|-----------------------|-----------------|------------|----------------|-----------|--------------|---------|
| Random Forest         | 0.942           | 0.991      | 0.943          | 0.951     | 0.535        | 0.781   |
| Regress√£o Log√≠stica   | 0.948           | 0.869      | 0.941          | 0.794     | 0.633        | 0.700   |

### An√°lise
- O **Random Forest** apresentou excelente desempenho em treino e teste (acur√°cia ~0.94 e AUC ~0.95), mas sofreu uma queda brusca na acur√°cia no OOT (~0.53), embora tenha mantido AUC razo√°vel (~0.78).  
  Isso sugere **overfitting temporal**, ou seja, o modelo aprendeu muito bem padr√µes do per√≠odo de treino/teste, mas n√£o generalizou para dados futuros.  

- A **Regress√£o Log√≠stica** teve desempenho inferior em treino/teste, mas mostrou maior estabilidade no OOT (acur√°cia ~0.63 e AUC ~0.70).
Como o objetivo √© garantir **capacidade preditiva temporal** e **estabilidade fora da amostra**, mesmo com menor poder discriminativo, o melhor modelo pra esse cen√°rio √© a **Regress√£o Log√≠stica**.

### Curva ROC ‚Äì Regress√£o Log√≠stica

A curva ROC avalia o desempenho do modelo em diferentes limiares de decis√£o:

- **Eixo X (1 - Especificidade > Taxa de Falsos Positivos):** mostra a propor√ß√£o de clientes que **n√£o s√£o churn**, mas foram classificados como churn. Quanto mais √† esquerda, melhor (menos falsos positivos).
- **Eixo Y (Sensibilidade > Taxa de Verdadeiros Positivos):** mostra a propor√ß√£o de clientes que **s√£o churn** e foram corretamente identificados. Quanto mais alto, melhor (mais acertos).

A linha pontilhada diagonal representa um classificador aleat√≥rio (AUC = 0.5).  
Quanto mais a curva se afasta dessa linha em dire√ß√£o ao canto superior esquerdo, maior o poder discriminativo do modelo.

No caso da regress√£o log√≠stica:
- **Treino e Teste:** curvas altas, confirmando bom aprendizado e generaliza√ß√£o.  
- **OOT:** curva mais pr√≥xima da diagonal, com AUC ~0.70. Isso significa que, ao comparar aleatoriamente um cliente churn e um n√£o churn, o modelo tem **70% de chance de atribuir maior probabilidade ao churn verdadeiro**.  
Na pr√°tica, o modelo mant√©m capacidade preditiva fora da amostra, ainda que com menor precis√£o que nos dados hist√≥ricos.

## 11. Principais  Insights sobre o Churn

O gr√°fico abaixo mostra as vari√°veis mais relevantes da regress√£o log√≠stica para explicar o churn.  
A interpreta√ß√£o dos coeficientes indica os seguintes perfis:

### üîç Insights

- **Maior chance de churn**
  - Tempo de relacionamento = **1 ano**
  - Pedidos por ano relativo = **0 a 3**
  - Categoria de compra preferida = **Laptops e acess√≥rios**
  - 
**Perfil:** Clientes relativamente novos, com baixo engajamento (poucos pedidos) e foco em categorias de maior valor. S√£o consumidores que ainda n√£o consolidaram v√≠nculo com a empresa e podem migrar facilmente para concorrentes.

- **Menor chance de churn (n√£o churn)**
  - Tempo de relacionamento = **0 anos**
  - Pedidos por ano relativo = **4 a 6**
  - N√≠vel da cidade = **3 (cidades pequenas ou menores)**
**Perfil:** Clientes rec√©m-adquiridos, mas j√° engajados com frequ√™ncia de compras maior. Tendem a estar em cidades menores, onde a concorr√™ncia √© menos intensa e o relacionamento com a marca se fortalece mais r√°pido.

### A√ß√µes recomendadas

- **Reduzir churn em clientes de risco**
  - Criar campanhas de reten√ß√£o espec√≠ficas para clientes no **1¬∫ ano de relacionamento**.
  - Usar os canais j√° existentes para refor√ßar relacionamento
  - Benef√≠cios exclusivos para clientes das cidades maiores (ex.: entregas mais r√°pidas, suporte premium)
  - Incentivar aumento da frequ√™ncia de compras (programas de pontos, descontos progressivos).
  - Oferecer benef√≠cios exclusivos em categorias de **laptops e acess√≥rios** (ex.: garantia estendida, suporte premium).

## Serializa√ß√£o do Modelo
Para disponibilizar o modelo num app interativo, foi necess√°rio salvar tanto o pipeline treinado quanto as features utilizadas em formato serializado (`.pkl`).  
Esse processo garante que o modelo possa ser carregado e executado diretamente na aplica√ß√£o, sem precisar reprocessar ou re-treinar os dados.

## Aplica√ß√£o Pr√°tica (Streamlit)

Este projeto foi desenvolvido com foco em disponibilizar as informa√ß√µes de forma pr√°tica e acess√≠vel no dia dia das empresas.  
Para isso, foi criado um **aplicativo em Streamlit** que permite visualizar e interagir com os resultados do modelo de churn.
https://app-predicao-churn-ecommerce.streamlit.app/ (clique com o bot√£o direito ‚Üí Abrir em nova guia)

###  Lista de clientes em tempo real
- O app mostra uma **tabela com os clientes e suas respectivas probabilidades de churn**, acompanhada da **a√ß√£o recomendada** para cada perfil.  
- Essa lista pode ser facilmente integrada √† rotina da equipe de **[ex.: marketing, atendimento, CRM]**, servindo como guia para execu√ß√£o das a√ß√µes de reten√ß√£o.  


###  Simula√ß√£o individual
- Al√©m da vis√£o geral, o app oferece uma funcionalidade de **simula√ß√£o individual**.  
- Nela, √© poss√≠vel **inputar valores das vari√°veis** (tempo de relacionamento, pedidos por ano, categoria preferida, etc.) e obter  a **probabilidade de churn** para aquele perfil espec√≠fico.  
- Isso permite testar cen√°rios e entender como diferentes caracter√≠sticas impactam o risco de churn.

###  Uso no dia a dia
- **Priorizar clientes de maior risco**: direcionar campanhas e esfor√ßos de reten√ß√£o para quem tem maior probabilidade de churn.  
- **Planejar a√ß√µes personalizadas**: usar as recomenda√ß√µes do modelo para definir estrat√©gias espec√≠ficas por perfil.  
- **Simular estrat√©gias**: avaliar como mudan√ßas no comportamento (ex.: aumento de pedidos por ano) podem reduzir o risco de churn.  
- **Apoiar decis√µes r√°pidas**: fornecer √† equipe uma ferramenta pr√°tica e visual, sem necessidade de conhecimento t√©cnico em modelagem.

## 12 Conclus√£o

Este projeto mostrou a import√¢ncia de aproveitar  melhor os dados j√° dispon√≠veis **criando novas features** e aplicar **discretiza√ß√£o** para melhorar a capacidade do modelo.  
Mesmo sem adicionar novas fontes de informa√ß√£o, conseguimos aumentar o poder preditivo apenas com criatividade na forma de tratar e transformar os dados.

No ambiente real, nem sempre teremos todas as informa√ß√µes √† m√£o, mas com criatividade √© poss√≠vel extrair valor e aumentar o poder preditivo com o que temos.

Tamb√©m refor√ßamos a relev√¢ncia de **comparar diferentes modelos de Machine Learning** e escolher o melhor com base em m√©tricas consistentes, garantindo maior confiabilidade nos resultados.

Por fim, o foco foi transformar todo esse processo em algo **pr√°tico para o dia a dia da empresa**. Para isso, desenvolvemos um **aplicativo em Streamlit** que apresenta a lista de clientes com suas probabilidades de churn e a√ß√µes recomendadas, al√©m de permitir simula√ß√µes individuais. Assim, o modelo deixa de ser apenas uma an√°lise t√©cnica e passa a ser uma ferramenta √∫til para apoiar decis√µes estrat√©gicas.

## Tecnologias Utilizadas

- **Python** ‚Äì linguagem principal para an√°lise e modelagem.  
- **Streamlit** ‚Äì cria√ß√£o do aplicativo interativo para disponibilizar os resultados.  
- **VS Code** ‚Äì ambiente de desenvolvimento.

###  Bibliotecas principais
- **pandas** ‚Äì manipula√ß√£o e an√°lise de dados.  
- **numpy** ‚Äì opera√ß√µes num√©ricas e vetoriais.  
- **matplotlib / seaborn** ‚Äì visualiza√ß√£o de gr√°ficos e insights.  
- **scikit-learn** ‚Äì modelagem e avalia√ß√£o de algoritmos de Machine Learning.  
  - `linear_model` ‚Äì regress√£o log√≠stica.  
  - `ensemble` ‚Äì testes com modelos de conjunto.  
  - `tree` ‚Äì testes com √°rvores de decis√£o.  
  - `pipeline` ‚Äì organiza√ß√£o do fluxo de pr√©-processamento e modelagem.  
  - `SimpleImputer` ‚Äì tratamento de valores ausentes.  
- **feature-engine** ‚Äì discretiza√ß√£o e encoding de vari√°veis.







